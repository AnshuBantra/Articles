{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unleashing the Power of Python Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python provides several constructs for creating iterators, with generators being one of the most powerful, nifty, and efficient. They allow you to iterate through a sequence of values, but unlike a regular function, they yield values one at a time, pausing their state between each yield. This makes them super efficient for large datasets or infinite sequences since they only compute values as you need them.\n",
    "\n",
    "#### Key Concepts\n",
    "- **`yield` Keyword:** The `yield` statement is used to produce a value and pause the function's execution, maintaining its state for subsequent calls.\n",
    "- **Lazy Evaluation:** Generators evaluate data lazily, meaning they generate values only as needed.\n",
    "\n",
    "Let us look at a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mnext\u001b[39m(gen))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mnext\u001b[39m(gen))\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m# Generator object indicating with \"StopIteration\" error that it is done\u001b[39;00m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def generator_example(): # Generator Function\n",
    "    yield 1\n",
    "    yield 2\n",
    "    yield 3\n",
    "\n",
    "gen = generator_example() # Creating instance of generator\n",
    "\n",
    "print(next(gen)) # Extracting values from gen object one at a time\n",
    "print(next(gen))\n",
    "print(next(gen))\n",
    "print(next(gen)) # Generator object indicating with \"StopIteration\" error that it is done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the generator function generator_example uses yield instead of return. Each time yield is called, the generator's state is saved, and the value is returned to the caller. When next() is called again, the generator resumes right after the yield. This iteration goes on till the generator has exhausted its limits, like in the 4th yield call here, which raised a `StopIteration` error\n",
    "\n",
    "However, the same can be achieved more efficiently with an iterator like `For Loop` without having to worry about when the end of the generator is reached. i.e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "gen = generator_example() # Creating instance of generator\n",
    "\n",
    "for val in gen: # Looping over generator to fetch its values\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generators in Python are often described as using lazy evaluation because they don't compute values until needed. Instead of producing all the values at once and storing them in memory, generators yield values one at a time and only when requested.\n",
    "\n",
    "Imagine you have a huge dataset. Using a generator, Python will calculate each item in the sequence only when you iterate over it, rather than calculating and storing the entire sequence in memory upfront. This makes them memory-efficient and perfect for handling large or even infinite datasets.\n",
    "\n",
    "Lazy but brilliant - right when you need them, they spring into action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Comprehension\n",
    "Generator comprehension is a powerful, concise way to create generators in Python. Similar to list comprehensions, generator comprehensions allow you to define a generator in a single line. However, while list comprehensions return a list, generator comprehensions return a generator object, which yields items one at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object <genexpr> at 0x0000014877B75000>\n",
      "<class 'generator'>\n"
     ]
    }
   ],
   "source": [
    "number_generator = (_ for _ in range(1000001))\n",
    "print(number_generator)\n",
    "print(type(number_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefits of Generators\n",
    "Generators are like that efficient buddy who gets things done with minimal fuss and maximum efficiency:\n",
    "\n",
    "**1. Memory Efficiency:** Generators produce values one at a time, only when they are requested, rather than generating an entire sequence at once. This means you don't have to load all the data into memory, which is particularly helpful when working with large datasets.\n",
    "Example: If you're processing a file with millions of lines, loading the entire file into memory would be inefficient or even infeasible. A generator reads and processes one line at a time, reducing memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of number_list      is 8448728 bytes\n",
      "Size of number_generator is     192 bytes\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "number_list = [_ for _ in range(1000001)]\n",
    "print(f'Size of number_list      is {sys.getsizeof(number_list):>7} bytes')\n",
    "\n",
    "number_generator = (_ for _ in range(1000001)) # Generator for numbers 0 to 1000000\n",
    "print(f'Size of number_generator is {sys.getsizeof(number_generator):>7} bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Infinite Sequences:** Generators can be used to model infinite sequences, such as the natural numbers or Fibonacci Series, etc. This isn't possible with lists or other data structures because they would run out of memory. In the below example, we see how easily we could create an infinite Fibonacci Series, while only consuming ~200 bytes of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object fibonacci_generator at 0x0000014878381A40>\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# Define a Generator Function for Infinite Fibonacci Series\n",
    "def fibonacci_generator():\n",
    "    a, b = 0, 1\n",
    "    while True:\n",
    "        yield a\n",
    "        a, b = b, (a+b)\n",
    "\n",
    "# Create the generator object\n",
    "gen = fibonacci_generator()\n",
    "print(gen)\n",
    "print(sys.getsizeof(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Lazy Evaluation:** Since generators compute values on the fly, they're great for scenarios where you might not need all the values upfront. This leads to better performance because it avoids unnecessary calculations.\n",
    "\n",
    "In the above example, we created a generator for the infinite Fibonacci Series. Utilizing the same, in the below example we'll extract and produce the first 10 elements from the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1, 1, 2, 3, 5, 8, 13, 21, 34, "
     ]
    }
   ],
   "source": [
    "# Define a Generator Function for Infinite Fibonacci Series\n",
    "def fibonacci_generator():\n",
    "    a, b = 0, 1\n",
    "    while True:\n",
    "        yield a\n",
    "        a, b = b, (a+b)\n",
    "\n",
    "# Create the generator object\n",
    "gen = fibonacci_generator()\n",
    "\n",
    "# Get the first 5 numbers from the generator\n",
    "for _ in range(10):\n",
    "    print(next(gen), end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, even better we can use Python libraries like itertools to slice a generator object to get specific parts of the generator object. In the below example, we extract, the 10th to 20th elements from the infinite Fibonacci Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of fibo_10_20 is 184 bytes\n",
      "[34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181]\n"
     ]
    }
   ],
   "source": [
    "import itertools as itt\n",
    "\n",
    "gen = fibonacci_generator()\n",
    "fibo_10_20 = [*itt.islice(gen, 9, 20)] # use islice from itertools to slice 10th to 20th elements and expand them into a list\n",
    "\n",
    "print(f'Size of fibo_10_20 is {sys.getsizeof(fibo_10_20)} bytes')\n",
    "print(fibo_10_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Improved Performance:** Generators can improve performance by avoiding the overhead of creating a full list or sequence before processing can start. Since they yield items one at a time, execution can begin immediately, and you don't have to wait for all the data to be generated. This can lead to faster execution times, especially for operations involving large data sets. So, generators not only improve performance in terms of memory usage but also make your code more responsive.\n",
    "\n",
    "*Example:* If you're streaming data from a sensor or external API, a generator allows you to process the data in real time as it comes in, rather than waiting for the entire dataset. Or you could easily read a very large log file one line at a time, without having to load its entire contents into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error lines: 151\n"
     ]
    }
   ],
   "source": [
    "# Generator function to read log file and yield lines with errors\n",
    "def read_large_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if \"ERROR\" in line:\n",
    "                yield line\n",
    "\n",
    "log_file = 'large_log_file.txt' # Hypothetical Log File\n",
    "error_lines = list(read_large_file(log_file))\n",
    "print(f\"Total error lines: {len(error_lines)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Simplified Code and Iteration:** Generators allow you to write cleaner and more readable code. Instead of managing iteration manually with counters and loops, generators let you focus on what you want to produce, and Python handles the iteration for you.\n",
    "\n",
    "It also provides with Encapsulation as Generators automatically remember the last position in the iteration, so you don't need to manage the state manually between calls. This makes them ideal for handling tasks that require maintaining an internal state over iterations, like reading through a large file or sequence of items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Pipelining or Chaining Generators:** Generators can be chained together to form a pipeline of operations. This allows you to process data in stages and can be very useful for tasks like data processing, where each stage of the pipeline processes one item at a time.\n",
    "\n",
    "*Example:* You could have a generator that generates even numbers and another that generates square roots of those even numbers. Each stage processes one item at a time, allowing for the efficient handling of large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.0),  (2, 1.41),  (4, 2.0),  (6, 2.45),  (8, 2.83),  (10, 3.16),  (12, 3.46),  (14, 3.74),  (16, 4.0),  (18, 4.24),  (20, 4.47),  (22, 4.69),  (24, 4.9),  (26, 5.1),  (28, 5.29),  "
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def even_numbers(numbers):\n",
    "    for n in numbers:\n",
    "        if n % 2 == 0:\n",
    "            yield n\n",
    "\n",
    "def even_sqrt(numbers):\n",
    "    for n in numbers:\n",
    "        yield round(math.sqrt(n), 2)\n",
    "\n",
    "# Chain them together\n",
    "numbers = range(30)\n",
    "for num in zip(even_numbers(numbers), even_sqrt(even_numbers(numbers))):\n",
    "    print(num, end=',  ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In conclusion, Python generators offer a powerful and memory-efficient way to work with large datasets and complex computations. By yielding values one at a time, generators allow for lazy evaluation and can significantly optimize performance. Whether you're dealing with infinite sequences or simply want to improve the readability and maintainability of your code, generators are an essential tool \n",
    "in any Python programmer's toolkit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
